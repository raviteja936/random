{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(230)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data - Load MNIST Train and Test datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data type: uint8;\n",
      "Training data shape: (60000, 28, 28)\n",
      "\n",
      "Test data type: uint8;\n",
      "Test data shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data type: %s;\\nTraining data shape: %s\" % (x_train.dtype, x_train.shape))\n",
    "print(\"\\nTest data type: %s;\\nTest data shape: %s\" % (x_test.dtype, x_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(x, y):\n",
    "    x = tf.cast(x, tf.float32)/255.0\n",
    "    y = tf.cast(y, tf.int64)\n",
    "    return x, y\n",
    "\n",
    "def preprocess(x, y, mode=\"train\"):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    ds = ds.map(preprocess_features)\n",
    "    if mode == \"train\":\n",
    "        ds = ds.shuffle(10000)\n",
    "    ds = ds.batch(256)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = preprocess(x_train, y_train)\n",
    "val_ds = preprocess(x_test, y_test, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1 - Default Sequential Model from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Reshape(target_shape=(28 * 28,), input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2 - Custom Model inherited from Keras Model Class  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, in_shape, layers, out_shape):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model_layers = []\n",
    "        self.model_layers.append(tf.keras.layers.Reshape(target_shape=(in_shape,)))\n",
    "        for layer in layers:\n",
    "            units = layer[0]\n",
    "            activation = layer[1]\n",
    "            self.model_layers.append(tf.keras.layers.Dense(units=units, activation=activation))\n",
    "        self.model_layers.append(tf.keras.layers.Dense(units=out_shape, activation=None))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = inputs\n",
    "        for layer in self.model_layers:\n",
    "            outputs = layer(inputs)\n",
    "            inputs = outputs\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_shape = 28*28\n",
    "ls = [[100, \"relu\"], [100, \"relu\"]]\n",
    "out_shape = 10\n",
    "model = Model(in_shape, ls, out_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1 - Default Keras API using .compile and .fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"accuracy\"]\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 235 steps, validate for 40 steps\n",
      "Epoch 1/5\n",
      "235/235 [==============================] - 9s 40ms/step - loss: 0.4343 - accuracy: 0.8827 - val_loss: 0.1995 - val_accuracy: 0.9398\n",
      "Epoch 2/5\n",
      "235/235 [==============================] - 9s 37ms/step - loss: 0.1707 - accuracy: 0.9512 - val_loss: 0.1354 - val_accuracy: 0.9579\n",
      "Epoch 3/5\n",
      "235/235 [==============================] - 9s 39ms/step - loss: 0.1227 - accuracy: 0.9635 - val_loss: 0.1094 - val_accuracy: 0.9647\n",
      "Epoch 4/5\n",
      "235/235 [==============================] - 9s 36ms/step - loss: 0.0952 - accuracy: 0.9715 - val_loss: 0.0968 - val_accuracy: 0.9689\n",
      "Epoch 5/5\n",
      "235/235 [==============================] - 8s 36ms/step - loss: 0.0782 - accuracy: 0.9763 - val_loss: 0.0913 - val_accuracy: 0.9703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4428380b00>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=metrics)\n",
    "model.fit(train_ds, epochs=epochs, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2 - Custom Training using Gradient Tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(x)\n",
    "        loss = loss_fn(y, predictions)\n",
    "    \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def val_step(x, y):\n",
    "    predictions = model(x)\n",
    "    loss = loss_fn(y, predictions)\n",
    "\n",
    "    val_loss(loss)\n",
    "    val_accuracy(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.43431714177131653, Accuracy: 88.27000427246094, Val Loss: 0.19948408007621765, Val Accuracy: 93.9800033569336\n",
      "Epoch 2, Loss: 0.1707475483417511, Accuracy: 95.11666870117188, Val Loss: 0.13541637361049652, Val Accuracy: 95.79000091552734\n",
      "Epoch 3, Loss: 0.12271910905838013, Accuracy: 96.35499572753906, Val Loss: 0.10936269909143448, Val Accuracy: 96.47000122070312\n",
      "Epoch 4, Loss: 0.09524733573198318, Accuracy: 97.1483383178711, Val Loss: 0.09678876399993896, Val Accuracy: 96.88999938964844\n",
      "Epoch 5, Loss: 0.07820867747068405, Accuracy: 97.63333129882812, Val Loss: 0.09128781408071518, Val Accuracy: 97.02999877929688\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    val_loss.reset_states()\n",
    "    val_accuracy.reset_states()\n",
    "\n",
    "    for x, y in train_ds:\n",
    "        train_step(x, y)\n",
    "\n",
    "    for val_x, val_y in val_ds:\n",
    "        val_step(val_x, val_y)\n",
    "\n",
    "    print('Epoch {}, Loss: {}, Accuracy: {}, Val Loss: {}, Val Accuracy: {}'.format(epoch + 1,\n",
    "                        train_loss.result(),\n",
    "                        train_accuracy.result() * 100,\n",
    "                        val_loss.result(),\n",
    "                        val_accuracy.result() * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
