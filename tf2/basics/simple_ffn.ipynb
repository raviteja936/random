{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, optimizers, metrics, datasets, Sequential\n",
    "tf.random.set_seed(230)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data - Load MNIST Train and Test datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data type: uint8;\n",
      "Training data shape: (60000, 28, 28)\n",
      "\n",
      "Test data type: uint8;\n",
      "Test data shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data type: %s;\\nTraining data shape: %s\" % (x_train.dtype, x_train.shape))\n",
    "print(\"\\nTest data type: %s;\\nTest data shape: %s\" % (x_test.dtype, x_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(x, y):\n",
    "    x = tf.cast(x, tf.float32)/255.0\n",
    "    y = tf.cast(y, tf.int64)\n",
    "    return x, y\n",
    "\n",
    "def preprocess(x, y, mode=\"train\"):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    ds = ds.map(preprocess_features)\n",
    "    if mode == \"train\":\n",
    "        ds = ds.shuffle(10000)\n",
    "    ds = ds.batch(256)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = preprocess(x_train, y_train)\n",
    "val_ds = preprocess(x_test, y_test, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1 - Default Sequential Model from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    layers.Reshape(target_shape=(28 * 28,), input_shape=(28, 28)),\n",
    "    layers.Dense(100, activation=\"relu\"),\n",
    "    layers.Dense(100, activation=\"relu\"),\n",
    "    layers.Dense(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2 - Custom Model inherited from Keras Model Class  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, in_shape, layers, out_shape):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model_layers = []\n",
    "        self.model_layers.append(tf.keras.layers.Reshape(target_shape=(in_shape,)))\n",
    "        for layer in layers:\n",
    "            units = layer[0]\n",
    "            activation = layer[1]\n",
    "            self.model_layers.append(tf.keras.layers.Dense(units=units, activation=activation))\n",
    "        self.model_layers.append(tf.keras.layers.Dense(units=out_shape, activation=None))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = inputs\n",
    "        for layer in self.model_layers:\n",
    "            outputs = layer(inputs)\n",
    "            inputs = outputs\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_shape = 28*28\n",
    "ls = [[100, \"relu\"], [100, \"relu\"]]\n",
    "out_shape = 10\n",
    "model = Model(in_shape, ls, out_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Optimizer, Loss and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam(0.001)\n",
    "loss = tf.losses.CategoricalCrossentropy(from_logits=True),\n",
    "metrics = [\"accuracy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 235 steps, validate for 40 steps\n",
      "235/235 [==============================] - 10s 42ms/step - loss: 461325.2964 - accuracy: 1.0000 - val_loss: 642036.5078 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc88c6d1ac8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "model.fit(train_ds, epochs=1, validation_data=val_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
