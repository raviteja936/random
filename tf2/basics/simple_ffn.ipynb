{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(230)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data - Load MNIST Train and Test datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data type: uint8;\n",
      "Training data shape: (60000, 28, 28)\n",
      "\n",
      "Test data type: uint8;\n",
      "Test data shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data type: %s;\\nTraining data shape: %s\" % (x_train.dtype, x_train.shape))\n",
    "print(\"\\nTest data type: %s;\\nTest data shape: %s\" % (x_test.dtype, x_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(x, y):\n",
    "    x = tf.cast(x, tf.float32)/255.0\n",
    "    y = tf.cast(y, tf.int64)\n",
    "    return x, y\n",
    "\n",
    "def preprocess(x, y, mode=\"train\"):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    ds = ds.map(preprocess_features)\n",
    "    if mode == \"train\":\n",
    "        ds = ds.shuffle(10000)\n",
    "    ds = ds.batch(256)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = preprocess(x_train, y_train)\n",
    "val_ds = preprocess(x_test, y_test, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1 - Default Sequential Model from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(28 * 28,), input_shape=(28, 28)),\n",
    "    layers.Dense(100, activation=\"relu\"),\n",
    "    layers.Dense(100, activation=\"relu\"),\n",
    "    layers.Dense(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2 - Custom Model inherited from Keras Model Class  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, in_shape, layers, out_shape):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model_layers = []\n",
    "        self.model_layers.append(tf.keras.layers.Reshape(target_shape=(in_shape,)))\n",
    "        for layer in layers:\n",
    "            units = layer[0]\n",
    "            activation = layer[1]\n",
    "            self.model_layers.append(tf.keras.layers.Dense(units=units, activation=activation))\n",
    "        self.model_layers.append(tf.keras.layers.Dense(units=out_shape, activation=None))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = inputs\n",
    "        for layer in self.model_layers:\n",
    "            outputs = layer(inputs)\n",
    "            inputs = outputs\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_shape = 28*28\n",
    "ls = [[100, \"relu\"], [100, \"relu\"]]\n",
    "out_shape = 10\n",
    "model = Model(in_shape, ls, out_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1 - Default Keras API using .compile and .fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"accuracy\"]\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 235 steps, validate for 40 steps\n",
      "Epoch 1/5\n",
      "235/235 [==============================] - 11s 47ms/step - loss: 0.4651 - accuracy: 0.8709 - val_loss: 0.2112 - val_accuracy: 0.9358\n",
      "Epoch 2/5\n",
      "235/235 [==============================] - 9s 37ms/step - loss: 0.1904 - accuracy: 0.9444 - val_loss: 0.1479 - val_accuracy: 0.9559\n",
      "Epoch 3/5\n",
      "235/235 [==============================] - 9s 39ms/step - loss: 0.1373 - accuracy: 0.9600 - val_loss: 0.1208 - val_accuracy: 0.9624\n",
      "Epoch 4/5\n",
      "235/235 [==============================] - 9s 38ms/step - loss: 0.1070 - accuracy: 0.9681 - val_loss: 0.1048 - val_accuracy: 0.9668\n",
      "Epoch 5/5\n",
      "235/235 [==============================] - 9s 39ms/step - loss: 0.0866 - accuracy: 0.9740 - val_loss: 0.0961 - val_accuracy: 0.9694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc864637f28>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=metrics)\n",
    "model.fit(train_ds, epochs=epochs, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2 - Custom Training using Gradient Tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(x)\n",
    "        loss = loss_fn(y, predictions)\n",
    "    \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def val_step(x, y):\n",
    "    predictions = model(x)\n",
    "    loss = loss_fn(y, predictions)\n",
    "\n",
    "    val_loss(loss)\n",
    "    val_accuracy(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0, Accuracy: 0.0, Val Loss: 0.10248025506734848, Val Accuracy: 97.19000244140625\n",
      "Epoch 2, Loss: 0.0, Accuracy: 0.0, Val Loss: 0.10953875631093979, Val Accuracy: 97.1500015258789\n",
      "Epoch 3, Loss: 0.0, Accuracy: 0.0, Val Loss: 0.10380174219608307, Val Accuracy: 97.3699951171875\n",
      "Epoch 4, Loss: 0.0, Accuracy: 0.0, Val Loss: 0.10200326144695282, Val Accuracy: 97.39999389648438\n",
      "Epoch 5, Loss: 0.0, Accuracy: 0.0, Val Loss: 0.09920348972082138, Val Accuracy: 97.57999420166016\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    val_loss.reset_states()\n",
    "    val_accuracy.reset_states()\n",
    "\n",
    "    for x, y in train_ds:\n",
    "        train_step(x, y)\n",
    "\n",
    "    for val_x, val_y in val_ds:\n",
    "        val_step(val_x, val_y)\n",
    "\n",
    "    print('Epoch {}, Loss: {}, Accuracy: {}, Val Loss: {}, Val Accuracy: {}'.format(epoch + 1,\n",
    "                        train_loss.result(),\n",
    "                        train_accuracy.result() * 100,\n",
    "                        val_loss.result(),\n",
    "                        val_accuracy.result() * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
