{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, optimizers, metrics, datasets, Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data type: uint8; Training data shape: (60000, 28, 28)\n",
      "Test data type: uint8; Test data shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data type: %s; Training data shape: %s\" % (x_train.dtype, x_train.shape))\n",
    "print(\"Test data type: %s; Test data shape: %s\" % (x_test.dtype, x_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(x, y):\n",
    "    x = tf.cast(x, tf.float32) / 255.0\n",
    "    y = tf.cast(y, tf.int64)\n",
    "    return x, y\n",
    "\n",
    "def preprocess(x, y, mode=\"train\"):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    ds = ds.map(preprocess_features)\n",
    "    ds = ds.batch(256)\n",
    "    if mode == \"train\":\n",
    "        ds = ds.shuffle(10000)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = preprocess(x_train, y_train)\n",
    "val_ds = preprocess(x_test, y_test, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1 - Default Sequential Model from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    layers.Reshape(target_shape=(28 * 28,), input_shape=(28, 28)),\n",
    "    layers.Dense(100, activation='relu'),\n",
    "    layers.Dense(100, activation='relu'),\n",
    "    layers.Dense(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2 - Custom Model inherited from Keras Model Class  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO\n",
    "class Model(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model_layers = []\n",
    "        self.model_layers = [pipe_joint(params.train_path, params.layout[\"numeric\"], params.layout[\"categorical\"])]\n",
    "        for layer in params.dense_layers:\n",
    "            units = layer[0]\n",
    "            try:\n",
    "                activation = layer[1]\n",
    "            except IndexError:\n",
    "                activation = None\n",
    "            self.model_layers.append(tf.keras.layers.Dense(units=units, activation=activation))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = inputs\n",
    "        for layer in self.model_layers:\n",
    "            outputs = layer(inputs)\n",
    "            inputs = outputs\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer, Loss and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optimizers.Adam(0.001)\n",
    "loss = tf.losses.CategoricalCrossentropy(from_logits=True),\n",
    "metrics = [\"accuracy\", \"loss\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 500 steps, validate for 2 steps\n",
      "500/500 [==============================] - 26s 51ms/step - loss: 1238719.1207 - accuracy: 0.0000e+00 - val_loss: 1493293.3125 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fec9465f1d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=optimizers.Adam(0.001),\n",
    "                  loss=tf.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(train_ds.repeat(), epochs=1, steps_per_epoch=500,\n",
    "              validation_data=val_ds.repeat(),\n",
    "              validation_steps=2\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
